{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focus on attention head and etc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all constants \n",
    "D_MODEL = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9., 12.]])\n",
      "tensor([ 9., 12.])\n",
      "tensor([[ 3.],\n",
      "        [ 7.],\n",
      "        [11.]])\n",
      "tensor([ 3.,  7., 11.])\n",
      "tensor([ 3.,  7., 11.])\n"
     ]
    }
   ],
   "source": [
    "# understanding dimensions in pytorch\n",
    "a = torch.tensor([[1.0, 2.0],\n",
    "                  [3.0, 4.0],\n",
    "                  [5.0, 6.0]])\n",
    "print(torch.sum(a, dim=0, keepdim=True))\n",
    "print(torch.sum(a, dim=0))\n",
    "print(torch.sum(a, dim=1, keepdim=True))\n",
    "print(torch.sum(a, dim=1))\n",
    "print(torch.sum(a, dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.0000,  2.0000, -2.3300, -5.6600])\n",
      "tensor([    0.2663,     0.7238,     0.0095,     0.0003])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's understand softmax\n",
    "# softmax is a function that takes a vector of K real numbers and normalizes it into a probability distribution consisting of K probabilities proportional to the exponentials of the input numbers.\n",
    "x = torch.tensor([1.0,2.0,-2.33,-5.66])\n",
    "def softmax(x):\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x),dim = 0)\n",
    "\n",
    "print(x)\n",
    "print(softmax(x))\n",
    "torch.sum(softmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "tensor([[1., 3., 5.],\n",
      "        [2., 4., 6.]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[1., 3., 5.],\n",
      "        [2., 4., 6.]])\n",
      "torch.Size([2, 3])\n",
      "Props of tensor B transpose\n",
      "Original tensor shape: torch.Size([2, 1, 2])\n",
      "Transposed tensor shape (0, 1): torch.Size([1, 2, 2])\n",
      "Transposed tensor shape (0, 2): torch.Size([2, 1, 2])\n",
      "Transposed tensor shape (1, 2): torch.Size([2, 2, 1])\n",
      "Original tensor: tensor([[[1, 2]],\n",
      "\n",
      "        [[5, 6]]])\n",
      "Transposed tensor (0, 1): tensor([[[1, 2],\n",
      "         [5, 6]]])\n",
      "Transposed tensor (0, 2): tensor([[[1, 5]],\n",
      "\n",
      "        [[2, 6]]])\n",
      "Transposed tensor (1, 2): tensor([[[1],\n",
      "         [2]],\n",
      "\n",
      "        [[5],\n",
      "         [6]]])\n"
     ]
    }
   ],
   "source": [
    "# learn transpose\n",
    "a = torch.tensor([[1.0, 2.0],\n",
    "                  [3.0, 4.0],\n",
    "                  [5.0, 6.0]])\n",
    "print(a.shape)\n",
    "print(a.T)\n",
    "print(a.T.shape)\n",
    "print(torch.transpose(a, 0,1))\n",
    "print(torch.transpose(a, 0,1).shape)\n",
    "\n",
    "# Suppose we have 3 dimensional space\n",
    "print(\"Props of tensor B transpose\")\n",
    "import torch\n",
    "\n",
    "# Creating a 3D tensor\n",
    "tensor = torch.tensor([[[1, 2]], \n",
    "                       [[5, 6]]])\n",
    "\n",
    "# Transpose by specifying dimensions\n",
    "transposed_tensor_01 = tensor.transpose(0, 1)\n",
    "transposed_tensor_02 = tensor.transpose(0, 2)\n",
    "transposed_tensor_12 = tensor.transpose(1, 2)\n",
    "\n",
    "print(\"Original tensor shape:\", tensor.shape)\n",
    "print(\"Transposed tensor shape (0, 1):\", transposed_tensor_01.shape)\n",
    "print(\"Transposed tensor shape (0, 2):\", transposed_tensor_02.shape)\n",
    "print(\"Transposed tensor shape (1, 2):\", transposed_tensor_12.shape)\n",
    "print(\"Original tensor:\", tensor)\n",
    "print(\"Transposed tensor (0, 1):\", transposed_tensor_01)\n",
    "print(\"Transposed tensor (0, 2):\", transposed_tensor_02)\n",
    "print(\"Transposed tensor (1, 2):\", transposed_tensor_12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wq = torch.randn(D_MODEL, 2)\n",
    "wk = torch.randn((D_MODEL, 2))\n",
    "wv = torch.randn((D_MODEL, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4318, -0.8425],\n",
      "        [ 0.2391, -0.1908],\n",
      "        [-0.0873,  0.2944],\n",
      "        [-0.6815, -2.0473]])\n",
      "tensor([[-0.8148,  1.1438],\n",
      "        [ 0.6409, -0.3287],\n",
      "        [ 1.8310, -0.1735],\n",
      "        [ 1.0375,  0.0264]])\n",
      "tensor([[-0.3025,  0.5385],\n",
      "        [ 0.9228,  0.4266],\n",
      "        [-1.3744,  2.2100],\n",
      "        [-0.0363, -0.6207]])\n"
     ]
    }
   ],
   "source": [
    "print(wq)\n",
    "print(wk)\n",
    "print(wv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.9709, 9.6774]) tensor([-9.6715,  0.7413]) tensor([ 4.9507, -0.2445])\n"
     ]
    }
   ],
   "source": [
    "xwq = torch.matmul(x, wq)\n",
    "xwk = torch.matmul(x, wk)\n",
    "xwv = torch.matmul(x, wv)\n",
    "print(xwq, xwk, xwv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-20.4510)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_score = torch.matmul(xwq , xwk.T )/D_MODEL**0.5\n",
    "attention_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m attention_weights \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/personalproject/nlp_with_transformers/venv/lib/python3.11/site-packages/torch/nn/functional.py:1858\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1856\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1858\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1860\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "attention_weights = torch.nn.functional.softmax(attention_score, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'An': 0, 'This': 1, 'a': 2, 'for': 3, 'input': 4, 'is': 5, 'sentence': 6, 'test': 7}\n"
     ]
    }
   ],
   "source": [
    "sentence = \"This is a test sentence for An input\"\n",
    "dc = { s:i for i,s in enumerate(sorted(sentence.split(\" \")))}\n",
    "print(dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 5, 2, 7, 6, 3, 0, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "sentence_int = torch.tensor([dc[s] for s in sentence.split(\" \")])\n",
    "print(sentence_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=100 \n",
    "torch.manual_seed(1337)\n",
    "d_model = 3 \n",
    "embed = torch.nn.Embedding(vocab_size, d_model)\n",
    "embed_sentence = embed(sentence_int).detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(100, 3)\n",
      "torch.Size([8, 3])\n"
     ]
    }
   ],
   "source": [
    "print(embed)\n",
    "print(embed_sentence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_q , d_k, d_v = 2, 2, 4 # d_q and d_k should be of same size \n",
    "W_query = torch.nn.Parameter(torch.randn(d_model, d_q)) \n",
    "W_key = torch.nn.Parameter(torch.randn(d_model, d_k))\n",
    "W_value = torch.nn.Parameter(torch.randn(d_model, d_v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]),\n",
       " torch.Size([3, 2]),\n",
       " torch.Size([3, 4]),\n",
       " Parameter containing:\n",
       " tensor([[ 1.2038, -2.4643],\n",
       "         [ 0.0454, -1.0101],\n",
       "         [ 0.6570, -1.1417]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0126,  0.9385],\n",
       "         [ 1.7373, -0.4486],\n",
       "         [-0.3954, -0.7813]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.1125,  0.0228, -0.8634, -0.5311],\n",
       "         [-0.0858, -0.9778, -0.7297,  0.8962],\n",
       "         [ 0.0630, -0.6822, -0.3909, -0.6245]], requires_grad=True))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_query.shape, W_key.shape, W_value.shape, W_query, W_key, W_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.5433,  1.3488, -0.1396])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2 = embed_sentence[1]\n",
    "x_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.5433,  1.3488, -0.1396])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one token \n",
    "x_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for one token attention is \n",
    "query_2 = torch.matmul(x_2, W_query)\n",
    "key_2 = torch.matmul(x_2, W_key)\n",
    "value_2 = torch.matmul(x_2, W_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2]),\n",
       " torch.Size([2]),\n",
       " torch.Size([4]),\n",
       " tensor([ 1.8273, -5.0062], grad_fn=<SqueezeBackward4>),\n",
       " tensor([2.3790, 0.9524], grad_fn=<SqueezeBackward4>),\n",
       " tensor([-1.8415, -1.1885, -2.2621,  0.4764], grad_fn=<SqueezeBackward4>))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_2.shape, key_2.shape, value_2.shape, query_2, key_2, value_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = embed_sentence @ W_key\n",
    "queries = embed_sentence @ W_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 2]),\n",
       " torch.Size([8, 2]),\n",
       " tensor([[ 1.0886, -1.1596],\n",
       "         [ 2.3790,  0.9524],\n",
       "         [-0.0431,  0.5848],\n",
       "         [ 2.3434, -0.6660],\n",
       "         [ 2.4786,  1.4268],\n",
       "         [-2.1581,  2.1002],\n",
       "         [ 0.0183,  0.4820],\n",
       "         [-0.0553,  1.0487]], grad_fn=<MmBackward0>),\n",
       " tensor([[-1.0566,  1.5941],\n",
       "         [ 1.8273, -5.0062],\n",
       "         [ 1.3893, -2.8295],\n",
       "         [ 1.0494, -3.3921],\n",
       "         [-0.9505,  0.6466],\n",
       "         [ 1.0095, -0.9320],\n",
       "         [-0.0218,  0.0358],\n",
       "         [-0.3320,  0.7124]], grad_fn=<MmBackward0>))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "keys.shape , queries.shape, keys, queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " one row shape  tensor(7.7941, grad_fn=<DotBackward0>)\n",
      "tensor(7.7941, grad_fn=<DotBackward0>) tensor(-0.4205, grad_fn=<DotBackward0>) tensor(-3.0061, grad_fn=<DotBackward0>) tensor(7.6164, grad_fn=<DotBackward0>) tensor(-2.6139, grad_fn=<DotBackward0>) tensor(-14.4576, grad_fn=<DotBackward0>) tensor(-2.3796, grad_fn=<DotBackward0>) tensor(-5.3509, grad_fn=<DotBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\" one row shape \", queries[1] @ keys[0].T )\n",
    "print(queries[1] @ keys[0].T,\n",
    "queries[1] @ keys[1].T ,\n",
    "queries[1] @ keys[2].T ,\n",
    "queries[1] @ keys[3].T ,\n",
    "queries[1] @ keys[4].T ,\n",
    "queries[1] @ keys[5].T ,\n",
    "queries[1] @ keys[6].T ,\n",
    "queries[1] @ keys[7].T )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( queries @ keys.T ).shape\n",
    "# this becomes similar to covariance matrix, noob thing but good\n",
    "# apply softmax to get attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmaxy_value =  torch.softmax(( queries @ keys.T )/ d_model ** 0.5, dim=-1 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    0.0053,     0.0168,     0.0525,     0.0039,     0.0245,     0.7699,\n",
       "             0.0460,     0.0811],\n",
       "        [    0.5211,     0.0045,     0.0010,     0.4703,     0.0013,     0.0000,\n",
       "             0.0015,     0.0003],\n",
       "        [    0.4134,     0.0369,     0.0097,     0.5050,     0.0184,     0.0001,\n",
       "             0.0120,     0.0045],\n",
       "        [    0.5242,     0.0183,     0.0087,     0.4265,     0.0077,     0.0001,\n",
       "             0.0110,     0.0035],\n",
       "        [    0.0285,     0.0308,     0.1016,     0.0172,     0.0349,     0.5709,\n",
       "             0.0945,     0.1216],\n",
       "        [    0.2252,     0.1534,     0.0456,     0.3589,     0.1259,     0.0059,\n",
       "             0.0499,     0.0352],\n",
       "        [    0.1200,     0.1233,     0.1262,     0.1193,     0.1244,     0.1337,\n",
       "             0.1258,     0.1274],\n",
       "        [    0.0471,     0.0878,     0.1200,     0.0454,     0.1047,     0.3357,\n",
       "             0.1137,     0.1456]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(softmaxy_value.shape)\n",
    "softmaxy_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8281, -0.8797],\n",
       "        [-0.0487, -0.7891],\n",
       "        [ 0.1550, -1.2509],\n",
       "        [-0.0693, -0.7196],\n",
       "        [ 0.6862, -0.8743],\n",
       "        [ 0.3556, -1.6522],\n",
       "        [ 0.3707, -1.1366],\n",
       "        [ 0.5136, -0.9952]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = embed_sentence @ W_query\n",
    "attention_score = softmaxy_value @ value\n",
    "attention_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
